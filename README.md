# Web Scraping - Produtos de Utilidade DomÃ©stica

Projeto de web scraping para coletar produtos do site **Utimix.com** (https://www.utimix.com/), baixar imagens organizadas por categoria e gerar planilhas com os dados coletados.

> ğŸ“– **Guia EspecÃ­fico**: Consulte o arquivo [GUIA_UTIMIX.md](GUIA_UTIMIX.md) para instruÃ§Ãµes detalhadas de configuraÃ§Ã£o.

## ğŸ“‹ Funcionalidades

- âœ… Scraping de produtos de mÃºltiplas categorias
- âœ… Download automÃ¡tico de imagens organizadas por categoria
- âœ… ExportaÃ§Ã£o para Excel e CSV
- âœ… Suporte a mÃºltiplas pÃ¡ginas
- âœ… Sistema de retry automÃ¡tico
- âœ… Logging detalhado
- âœ… Progresso visual com barras de progresso
- âœ… Respeita rate limiting e delays

## ğŸš€ InstalaÃ§Ã£o

1. Clone ou baixe este repositÃ³rio

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. Configurar URL Base

Edite `config.py` e defina a URL base do site:

```python
BASE_URL = "https://exemplo.com"
```

### 2. Identificar Seletores CSS (IMPORTANTE)

**OpÃ§Ã£o 1 - Script AutomÃ¡tico:**
```bash
python inspect_selectors.py
```

**OpÃ§Ã£o 2 - Manual:**
Use o DevTools do navegador (F12) para inspecionar os elementos HTML.

Depois, no arquivo `config.py`, configure os seletores CSS encontrados:

```python
SELECTORS = {
    'product_container': '.produto',        # Container de cada produto
    'product_name': '.produto-nome',        # Nome do produto
    'product_price': '.produto-preco',      # PreÃ§o
    'product_image': '.produto-imagem img', # Imagem
    'product_category': '.categoria',       # Categoria
    'product_link': 'a.produto-link',       # Link do produto
    'next_page': '.proxima-pagina',         # BotÃ£o prÃ³xima pÃ¡gina
}
```

**Dica:** Use o DevTools do navegador (F12) para inspecionar o HTML e encontrar os seletores corretos.

### 3. Configurar URLs das Categorias

Edite `main.py` e adicione as URLs das categorias que deseja fazer scraping:

```python
category_urls = [
    "https://exemplo.com/categoria1",
    "https://exemplo.com/categoria2",
    # Adicione mais URLs aqui
]
```

## ğŸ“– Como Usar

1. Configure o `config.py` com a URL base e seletores
2. Configure as URLs de categorias em `main.py`
3. Execute o script:

```bash
python main.py
```

O script irÃ¡:
- Coletar produtos das categorias configuradas
- Baixar imagens organizadas em pastas por categoria
- Gerar planilhas Excel e CSV na pasta `data/planilhas/`

## ğŸ“ Estrutura do Projeto

```
webScreaping/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py          # LÃ³gica principal de scraping
â”‚   â”œâ”€â”€ image_downloader.py # Download de imagens
â”‚   â”œâ”€â”€ data_exporter.py    # ExportaÃ§Ã£o para planilhas
â”‚   â””â”€â”€ utils.py            # FunÃ§Ãµes auxiliares
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/             # Imagens organizadas por categoria
â”‚   â””â”€â”€ planilhas/          # Planilhas geradas
â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes
â”œâ”€â”€ main.py                 # Script principal
â”œâ”€â”€ requirements.txt        # DependÃªncias
â””â”€â”€ README.md              # Este arquivo
```

## ğŸ“Š Estrutura dos Dados

Os produtos coletados terÃ£o a seguinte estrutura:

- `id`: ID Ãºnico do produto
- `nome`: Nome do produto
- `categoria`: Categoria do produto
- `preco`: PreÃ§o numÃ©rico
- `preco_original`: PreÃ§o no formato original do site
- `imagem_url`: URL da imagem original
- `imagem_local`: Caminho da imagem baixada
- `link`: Link do produto no site
- `data_coleta`: Data e hora da coleta

## âš ï¸ Importante

- **Respeite os termos de uso** do site que estÃ¡ fazendo scraping
- **Verifique o robots.txt** do site antes de iniciar
- **Use delays apropriados** entre requisiÃ§Ãµes (jÃ¡ configurado)
- **NÃ£o sobrecarregue o servidor** com muitas requisiÃ§Ãµes simultÃ¢neas

## ğŸ› ï¸ PersonalizaÃ§Ã£o

### Ajustar Delay entre RequisiÃ§Ãµes

No `config.py`:
```python
DELAY_BETWEEN_REQUESTS = 2  # Segundos
```

### Limitar Tamanho de Imagens

No `config.py`:
```python
MAX_IMAGE_SIZE = 10 * 1024 * 1024  # 10MB
RESIZE_IMAGES = True  # Redimensionar imagens grandes
MAX_IMAGE_DIMENSION = 2000  # Pixels
```

### Usar Selenium (para sites com JavaScript)

1. Instale o driver do navegador (ChromeDriver ou GeckoDriver)
2. No `config.py`:
```python
USE_SELENIUM = True
SELENIUM_DRIVER = "chrome"  # ou "firefox"
```

## ğŸ“ Logs

Os logs sÃ£o salvos em `scraping.log` e tambÃ©m exibidos no console.

## ğŸ¤ Contribuindo

Sinta-se livre para melhorar este projeto!

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais. Use com responsabilidade e respeitando os termos de uso dos sites.

